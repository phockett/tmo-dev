{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eVMI class dev\n",
    "20/11/20\n",
    "PH\n",
    "\n",
    "Build on `tmoDataBase` class for VMI data:\n",
    "\n",
    "- Constuct images\n",
    "- BG & subtractions\n",
    "- Masking\n",
    "- Covariance\n",
    "\n",
    "Previous work:\n",
    "\n",
    "- [classDemo](https://pswww.slac.stanford.edu/jupyterhub/user/phockett/notebooks/dev/classDemo_191120.ipynb#)\n",
    "- [Base class dev](https://pswww.slac.stanford.edu/jupyterhub/user/phockett/notebooks/dev/data_handling_dev_171120.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from h5py import File\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# HV imports\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh', 'matplotlib')\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "# Memory profiler - OPTIONAL for testing\n",
    "# https://timothymonteath.com/articles/monitoring_memory_usage/\n",
    "%load_ext memory_profiler\n",
    "%memit\n",
    "\n",
    "\n",
    "# Quick hack for slow internet connection!\n",
    "%autosave 36000\n",
    "\n",
    "\n",
    "# Import class - this requires pointing to the `tmoDataBase.py` file.\n",
    "# See https://github.com/phockett/tmo-dev\n",
    "\n",
    "# Import class from file\n",
    "import sys\n",
    "sys.path.append(r'/cds/home/p/phockett/dev/tmo-dev')\n",
    "import tmoDataBase as tb\n",
    "\n",
    "tb.setPlotDefaults()  # Set plot defaults (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set main data path\n",
    "baseDir = Path('/reg/data/ana15/tmo/tmolw0618/scratch/preproc/v2')\n",
    "\n",
    "# Setup class object and which runs to read.\n",
    "data = tb.tmoDataBase(fileBase = baseDir, runList = range(89,97+1), fileSchema='_preproc_elecv2')\n",
    "\n",
    "# The class has a bunch of dictionaries holding info on the data\n",
    "# data.runs['files']\n",
    "\n",
    "# Read in the files with h5py\n",
    "# There is very basic checking implemented currently, just to see if 'energies' is present.\n",
    "data.readFiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eVMI class dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- v 23/11/20 Basically working now with multiplefilter case, but possibly some issues with image renorm, and generally very ugly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev code for new class\n",
    "# Inherit from base class, just add evmi functionality here\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "class VMI(tb.tmoDataBase):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        # Run __init__ from base class\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Filter update - add multilevel filtering here.\n",
    "        # SHOULD propagate back to base class, but keep here for now as they're only applied to image processing.\n",
    "        # Set some default filters. Use self.setFilter() to change.\n",
    "        self.filters = {'signal':{'gas':True,\n",
    "                                  'desc': 'Signal filter.'},\n",
    "                        'bg':{'gas':False,\n",
    "                              'desc': 'Background filter.'},\n",
    "                        }\n",
    "\n",
    "    def filterData(self, filterOptions = {}, keys = None, dim = 'energies'):\n",
    "        \"\"\"Wrapper for filterData when using nested filter (v2, 23/11/20)\"\"\"\n",
    "\n",
    "        # Update filters if required\n",
    "        if filterOptions:\n",
    "            self.setFilter(filterOptions)\n",
    "\n",
    "        # Default to all datasets\n",
    "        if keys is None:\n",
    "            keys = self.runs['proc']\n",
    "\n",
    "        # Loop over filter sets and pass to base filterData() method.\n",
    "        for key in self.filters.keys():\n",
    "#             print(self.filters[key])\n",
    "            super().filterData(filterOptions = self.filters[key], keys = keys, dim = dim)\n",
    "\n",
    "            # Sort outputs to nested format\n",
    "            # Note this leaves current settings in self.data[key]['mask']\n",
    "            # These are STILL USED by histogram functions\n",
    "            for runKey in keys:\n",
    "                if key not in self.data[runKey].keys():\n",
    "                    self.data[runKey][key] = {}  # Init\n",
    "  \n",
    "\n",
    "# REMOVED since it's confusing - will always leave last filter mask set!\n",
    "#                 self.data[runKey][key]['mask'] = self.data[runKey]['mask'].copy()\n",
    "#                 self.data[runKey][key]['filter'] = self.filters[key]\n",
    "                \n",
    "                \n",
    "    # 1st go... running, but very slow.\n",
    "    # Would probably be faster to write this all for np.arrays, rather than using existing image2d.\n",
    "    def genVMI(self, bgSub=True, norm=True, keys=None, filterOptions={}, **kwargs):\n",
    "        \"\"\"Generate VMI images from event data, very basic hv.Image version.\"\"\"\n",
    "#         Quick test for run 89 - looks to be working, different images for each case.\n",
    "\n",
    "#         Need to improve:\n",
    "\n",
    "#         - Cmapping (maybe log10?)\n",
    "#         - Image processing, use gaussian kernel?\n",
    "#         - Move to Xarray dataset image stack for more advanced/careful processing...?\n",
    "\n",
    "# %%timeit\n",
    "# 24.3 s ± 370 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) LW06, Runs 89 - 97 (good only)\n",
    "        \n",
    "        # Default to all datasets\n",
    "        if keys is None:\n",
    "            keys = self.runs['proc']\n",
    "        \n",
    "        # Use existing image2d to generate images.\n",
    "        # This is possibly a bit slow, may be faster to rewrite 2D hist code (see old CIS codes for fast methods)\n",
    "        self.image2d(dim=['xc','yc'], filterOptions=filterOptions)  # keys=keys,\n",
    "        \n",
    "        # Restack\n",
    "        self.eVMI = {'full':{}, 'fullNorm':{}, 'bg':{}, 'bgNorm':{}, 'bgSub':{}}  # Define output dicts\n",
    "        for key in keys:\n",
    "            self.eVMI['full'][key] = self.data[key]['img']\n",
    "            \n",
    "            # Norm by no. events with gas.\n",
    "            # May want to norm by other factors too?\n",
    "            self.eVMI['fullNorm'][key] = self.data[key]['img'].transform(z=hv.dim('z')/np.array(self.data[key]['raw']['gas']).sum())\n",
    "            \n",
    "        # Background images - assumed to be same filter(s) but gas off\n",
    "        # NOTE: MAY NEED TO USE EXPLICT .copy() here? TBC\n",
    "        if bgSub:\n",
    "            filterOptions['gas'] = [False]  # Hard coded for now, should allow passing for more flexibility\n",
    "            self.image2d(dim=['xc','yc'], filterOptions=filterOptions)  # keys=keys,\n",
    "            \n",
    "            for key in keys:\n",
    "                self.eVMI['bg'][key] = self.data[key]['img']\n",
    "                self.eVMI['bgNorm'][key] = self.data[key]['img'].transform(z=hv.dim('z')/(~np.array(vmi.data[key]['raw']['gas']).astype(bool)).sum())\n",
    "        \n",
    "                # Direct data manipulation OK, returns numpy.ndarray\n",
    "                # Seems easiest way to go for now.\n",
    "                # But might be better with hv.transform methods?\n",
    "                # Didn't need dim in testing... but did here. Odd!\n",
    "                self.eVMI['bgSub'][key] = hv.Image(self.eVMI['fullNorm'][key].data['z'] - self.eVMI['bgNorm'][key].data['z'])\n",
    "                \n",
    "    \n",
    "    def genVMIXmulti(self, filterOptions={}, **kwargs):\n",
    "        \"\"\"Wrapper for genVMIX with multiple filter sets.\"\"\"\n",
    "        \n",
    "        if filterOptions is not None:\n",
    "            self.setFilter(filterOptions = filterOptions)\n",
    "        \n",
    "        # Run genVMIX for each filter set\n",
    "        # Note bgSub = False to avoid recursive run in current form (v2), but should update this\n",
    "        for item in self.filters.keys():\n",
    "            if self.verbose['main']:\n",
    "                print(f'Generating VMI images for filters: {item}')\n",
    "            \n",
    "            # Pass only single filter set here.\n",
    "            # Should change to avoid repetition of filtering.\n",
    "            self.genVMIX(bgSub=False, name=item, filterOptions = self.filters[item], **kwargs)\n",
    "            \n",
    "        \n",
    "    \n",
    "    # 2nd go, stack to Xarrays for processing        \n",
    "    def genVMIX(self, bgSub=True, norm=True, keys=None, filterOptions={}, \n",
    "                bins = (np.arange(0, 1048.1, 1)-0.5,)*2, dim=['yc','xc'], name = 'imgStack', **kwargs):\n",
    "        \"\"\"Generate VMI images from event data, very basic Xarray version.\n",
    "        \n",
    "        v2: allow for multi-level filter via genVMIXmulti wrapper, changed to super() for filter.\n",
    "            TODO: clean this up, currently using a nasty mix of new and old functionality.\n",
    "                  Also issues with ordering of functions, and whether some dicts. are already set.\n",
    "                  (Should filter all, then genVMIX.)\n",
    "        \n",
    "        v1: single filter set with hard-coded, recursive bg subtraction.\n",
    "        \"\"\"\n",
    " \n",
    "        # %%timeit\n",
    "        # 18.8 s ± 63 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) LW06, Runs 89 - 97 (good only)\n",
    "\n",
    "        # Default to all datasets\n",
    "        if keys is None:\n",
    "            keys = self.runs['proc']\n",
    "            \n",
    "        if filterOptions is not None:\n",
    "#             print(filterOptions)\n",
    "#             self.filterData(filterOptions = filterOptions)\n",
    "            super().filterData(filterOptions = filterOptions)  # Use super() for case of single filter set.\n",
    "        \n",
    "        # Current method below (as per Elio's code). For LW06 run 89 tests (~70k shots, ~7M events)\n",
    "        # Single shot: 1.88 s ± 15.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "        # All shots: 9.2 s ± 62.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "        # All shots, convert to int: 11.5 s ± 399 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "        # See also psana, opal.raw.image(evt)\n",
    "        \n",
    "        # Loop over all datasets\n",
    "        imgArray = np.empty([bins[0].size-1, bins[1].size-1, len(keys)])  # Set empty array\n",
    "        normVals = []\n",
    "        metrics = {'filterOptions':filterOptions.copy()}  # Log stuff to Xarray attrs\n",
    "        \n",
    "        for n, key in enumerate(keys):\n",
    "            # Initially assume mask can be used directly, but set to all True if not passed\n",
    "            # Will likely want more flexibility here later\n",
    "#             if mask is None:\n",
    "#             mask = np.ones_like(self.data[key]['raw'][dim[0]]).astype(bool)\n",
    "\n",
    "            # Check mask exists, set if not\n",
    "            if 'mask' not in self.data[key].keys():\n",
    "#                 self.filterData(keys=[key])\n",
    "                super().filterData(keys=[key])  # Use super() for case of single filter set.\n",
    "\n",
    "            # Note flatten or np.concatenate here to set to 1D, not sure if function matters as long as ordering consistent?\n",
    "            # Also, 1D mask selection will automatically flatten? This might be an issue for keeping track of channels?\n",
    "            # Should use numpy masked array...? Slower in testing.\n",
    "            d0 = np.array(self.data[key]['raw'][dim[0]])[self.data[key]['mask']].flatten()\n",
    "            d1 = np.array(self.data[key]['raw'][dim[1]])[self.data[key]['mask']].flatten()\n",
    "\n",
    "            # Stack to np array\n",
    "            imgArray[:,:,n] = np.histogram2d(d0,d1, bins = bins)[0]\n",
    "            \n",
    "            metrics[key] = {'shots':self.data[key]['raw'][dim[0]].shape,\n",
    "                            'selected':self.data[key]['mask'].sum(),\n",
    "                            'gas':np.array(self.data[key]['raw']['gas']).sum(),\n",
    "                            'events':d0.size,\n",
    "                            'norm':self.data[key]['mask'].size}\n",
    "            \n",
    "            normVals.append(self.data[key]['mask'].size) # shots selected - only for norm to no gas?\n",
    "            \n",
    "            if name not in self.data[key].keys():\n",
    "                self.data[key][name] = {}\n",
    "                \n",
    "            self.data[key][name]['metrics'] =  metrics[key].copy() # For mult filter case, push metrics to filter dict.\n",
    "            self.data[key][name]['mask'] = self.data[key]['mask'].copy()\n",
    "            \n",
    "#         return imgArray\n",
    "        # Convert to Xarray\n",
    "#         imgStack = xr.DataArray(imgArray, dims=[dim[0],dim[1],'run'], \n",
    "#                                 coords={dim[0]:bins[0][0:-1], dim[1]:bins[1][0:-1], 'run':keys},\n",
    "#                                 name = 'imgStack')\n",
    "        # 2nd attempt, swap dim labels & reverse y-dir. This maintains orientation for image plots.\n",
    "        imgStack = xr.DataArray(imgArray, dims=[dim[0],dim[1],'run'], \n",
    "                                coords={dim[0]:bins[0][:-1], dim[1]:bins[1][-2::-1], 'run':keys},\n",
    "                                name = name)\n",
    "\n",
    "        imgStack['norm'] = ('run', normVals)  # Store normalisation values\n",
    "        \n",
    "        if norm:\n",
    "            imgStack = imgStack/imgStack['norm']\n",
    "            imgStack.name = name  # Propagate name! Division kills it\n",
    "        \n",
    "        imgStack.attrs['metrics'] = metrics\n",
    "        \n",
    "        # Recursive call for bg calculation, but set bgSub=False\n",
    "        # CURRENTLY NOT WORKING - always get idential (BG only) results for both cases???\n",
    "        # As constructed ALWAYS assumes 1st call will have bgSub = True\n",
    "#         if bgSub:\n",
    "#             self.imgStack = imgStack.copy()  # May need .copy() here?\n",
    "#             filterOptions['gas'] = [False]  # Set bg as gas off, all other filter options identical\n",
    "#             self.genVMIX(bgSub=False, norm=norm, keys=keys, filterOptions=filterOptions, bins = bins, **kwargs)\n",
    "#         else:\n",
    "#             self.imgStackBG = imgStack.copy().rename('BG')\n",
    "\n",
    "        # Try keeping multiple results sets in stack instead.\n",
    "        # This is a little ugly, but working.\n",
    "        if not hasattr(self,'imgStack'):\n",
    "            # self.imgStack = []  # May need .copy() here?  # v1, set as list\n",
    "            self.imgStack = xr.Dataset()  # v2, set as xr.Dataset and append Xarrays to this\n",
    "        \n",
    "#         self.imgStack.append(imgStack.copy())  # May need .copy() here?  # v1\n",
    "        self.imgStack[name] = imgStack.copy()  # v2 using xr.Dataset - NOTE THIS KILLS METRICS!\n",
    "                                        # TODO: push to main dict, or coord?\n",
    "        \n",
    "        \n",
    "        if bgSub:\n",
    "            filterOptions['gas'] = [False]  # Set bg as gas off, all other filter options identical\n",
    "            self.genVMIX(bgSub=False, norm=norm, name=name+'BG', keys=keys, filterOptions=filterOptions, bins = bins, **kwargs)\n",
    "#             self.imgStack.append((self.imgStack[-2] - self.imgStack[-1]).rename(name + 'BGsub'))  # Use last 2 img sets for subtraction\n",
    "            self.imgStack[name + 'BGsub'] = ((self.imgStack[name] - self.imgStack[name+'BG']).rename(name + 'BGsub'))\n",
    "        \n",
    "        # Restack final output to NxNxm Xarray for easy manipulation/plotting.\n",
    "#         self.imgStack = self.imgStack.to_array(dim = 'type').rename('stacked')\n",
    "    \n",
    "#     def imgStacksub(self)\n",
    "    \n",
    "    # TODO: want to chain this for image plotting, but first set which array to use!\n",
    "    # TODO: options for which dataset to use, just hacked in duplicate code for now.\n",
    "    def restackVMIdataset(self):\n",
    "        # Restack image dataset to NxNxm Xarray for easy manipulation/plotting.\n",
    "        # Return rather than set internally...?\n",
    "  \n",
    "        if hasattr(self, 'imgReduce'):\n",
    "        # Restack, note transpose to force new dim ('type') to end.\n",
    "            # This currently matters for smoothing function with scipy gaussian_filter.\n",
    "            imgReduce = self.imgReduce.to_array(dim = 'type').rename('stacked')\n",
    "            #.transpose('yc','xc','run','type')\n",
    "\n",
    "            # Send new dim to end\n",
    "            dimStack = imgReduce.dims\n",
    "        #         self.imgStack = self.imgStack.transpose(*dimStack[1:],dimStack[0])\n",
    "            return imgReduce.transpose(*dimStack[1:],dimStack[0])\n",
    "        \n",
    "        else:\n",
    "            # Restack, note transpose to force new dim ('type') to end.\n",
    "            # This currently matters for smoothing function with scipy gaussian_filter.\n",
    "            imgStack = self.imgStack.to_array(dim = 'type').rename('stacked')\n",
    "            #.transpose('yc','xc','run','type')\n",
    "\n",
    "            # Send new dim to end\n",
    "            dimStack = imgStack.dims\n",
    "        #         self.imgStack = self.imgStack.transpose(*dimStack[1:],dimStack[0])\n",
    "            return imgStack.transpose(*dimStack[1:],dimStack[0])\n",
    "\n",
    "        \n",
    "    def downsample(self, step = [2,2], dims = ['xc','yc']):\n",
    "        \"\"\"Wrapper for xr.coarsen to downsample images by step.\n",
    "        \n",
    "        Set to trim boundaries, and sum over points. Coord system will be maintained.\n",
    "        \n",
    "        This will work for Dataset or Dataarray forms.\n",
    "        Currently set to use smoothed dataset if available, or imgStack if not.\n",
    "        \n",
    "        TODO: add some options here.\n",
    "        \"\"\"\n",
    "        \n",
    "        # v1 with list\n",
    "#         self.imgReduce = []\n",
    "        \n",
    "#         for n, item in enumerate(self.imgStack):\n",
    "# #             print(n)\n",
    "#             self.imgReduce.append(item.coarsen({dim[0]:step[0], dim[1]:step[1]}, boundary=\"trim\").sum())\n",
    "# #             self.imgReduce[n] = item.coarsen({dim[0]:step[0], dim[1]:step[1]}, boundary=\"trim\", keep_attrs=True).sum()\n",
    "    \n",
    "        # v2 with DataArray\n",
    "#         self.imgReduce = self.imgStack.coarsen({dims[0]:step[0], dims[1]:step[1]}, boundary=\"trim\").sum()\n",
    "#         for item in ['imgStack', 'imgSmoothed']:\n",
    "        if hasattr(self, 'imgSmoothed'):\n",
    "            self.imgReduce = self.imgSmoothed.coarsen({d:s for (d,s) in zip(dims,step)}, boundary=\"trim\").sum()\n",
    "        else:\n",
    "            self.imgReduce = self.imgStack.coarsen({d:s for (d,s) in zip(dims,step)}, boundary=\"trim\").sum()\n",
    "    \n",
    "    \n",
    "    def smooth(self, sigma = [1,1]):\n",
    "    # Try using scipy.ndimage for smoothing...\n",
    "    # Can use xr.apply_ufunc for this.\n",
    "    # NOTE: this applies to ALL DIMS, so set 0 for additional stacking dims!\n",
    "    # NOTE: this currently assumes dim ordering (not checked by name)\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html\n",
    "    \n",
    "    # smoothed = xr.apply_ufunc(gaussian_filter, imgReduce, 1)\n",
    "\n",
    "    # v1 for lists\n",
    "#         self.imgSmoothed = []\n",
    "\n",
    "#         # TODO: add options for which stack to smooth\n",
    "#         for item in enumerate(self.imgStack):\n",
    "#             self.imgSmoothed.append(xr.apply_ufunc(gaussian_filter, item, sigma))  # Final value is sigma [dim0,dim1...]\n",
    "    \n",
    "        # v2 with DataArray\n",
    "        # Set any additional dims to zero\n",
    "        if len(sigma) != self.imgStack.ndims:\n",
    "            sigma = np.pad(sigma, [0, self.imgStack.ndims - len(sigma)])\n",
    "            \n",
    "        self.imgSmoothed = (xr.apply_ufunc(gaussian_filter, self.imgStack, sigma))  # Final value is sigma [dim0,dim1...]\n",
    "    \n",
    "#     def fastHist(self, dims = ['xc','yc'], bins = [1048,1048], nullEvent = -9999):\n",
    "#         \"\"\"Generate 2D histogram via indexing. (Fast for small batches, but needs work for scale-up.)\n",
    "        \n",
    "#         NOTE: currently set for electron images, 1048x1048 bins.\n",
    "#         To explore: see notes below!\n",
    "#         \"\"\"\n",
    "        \n",
    "#         hist2D = np.zeros(bins+2)  # Sized for 1-indexed bins, plus final cell for invalid hits.\n",
    "\n",
    "#         # Index method... WAY FASTER single shot (orders of magnitude on np.histogram2d), moderately faster (~30%) all shots (but should be able to improve with Numba?)\n",
    "#         # Lots of options here, for now use .flatten() to allow for np.delete below. Masking may be faster?\n",
    "#         d0 = np.array(self.data[key]['raw'][dims[0]]).astype(int).flatten() \n",
    "#         d1 = np.array(self.data[key]['raw'][dims[1]]).astype(int).flatten()\n",
    "        \n",
    "#         #  easy way to drop -9999 \"no hits\"?\n",
    "#         d0 = np.delete(xhits, np.where(xhits == -9999))  # This only works for 1D case! May want to set NaNs instead?\n",
    "#         d1 = np.delete(yhits, np.where(yhits == -9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi = VMI(fileBase = baseDir, runList = range(89,97+1), fileSchema='_preproc_elecv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.readFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# 24.3 s ± 370 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) LW06, Runs 89 - 97 (good only)\n",
    "# vmi.genVMI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xarray img stack tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# 18.8 s ± 63 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) LW06, Runs 89 - 97 (good only)\n",
    "# 19.8 s ± 172 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) LW06, Runs 89 - 97 (good only), 23/11/20 version\n",
    "# vmi.genVMIX(filterOptions = {'gas':[True]})\n",
    "dims = ['yc','xc']\n",
    "vmi.genVMIXmulti(dims=dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(vmi.imgStack)  # == vmi.imgStackBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.imgStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtraction...\n",
    "vmi.imgStack['sub'] = vmi.imgStack['signal'] - vmi.imgStack['bg']\n",
    "vmi.imgStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.imgStack['signal'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.imgStack['signal'].norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.imgStack['bg'].norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.imgStack['bg'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.imgStack['signal'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently setting duplicate array... not sure why? Missing .copy() somewhere... but was previously working (single filter case)\n",
    "(vmi.imgStack['bg'] == vmi.imgStack['signal']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.data[89]['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.data[89]['bg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bug with metrics somewhere...?\n",
    "vmi.data[89]['signal']['metrics'] == vmi.data[89]['bg']['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.data[89]['signal']['mask'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vmi.restackVMIdataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.imgStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO FIX - something still not right here... metrics shouldn't be the same, although 'events' seems OK.\n",
    "# Inadvertently setting pointer somewhere...\n",
    "vmi.imgStack[0].metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.imgStack[1].metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.imgStack[1].norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vmi.imgStackBG*vmi.imgStackBG.norm).sel(run=89).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vmi.imgStack*vmi.imgStack.norm).sel(run=89).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = [2,2]\n",
    "dims = ['xc','yc']\n",
    "\n",
    "# list(zip(dims,step))\n",
    "{d:s for (d,s) in zip(dims,step)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try downsample & plot\n",
    "vmi.downsample(step=[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.imgReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgReduce = []\n",
    "# step=[2,2]\n",
    "\n",
    "# for n, item in enumerate(vmi.imgStack):\n",
    "#     print(n)\n",
    "# #     imgReduce[n] = \n",
    "#     test = item.coarsen({dim[0]:step[0], dim[1]:step[1]}, boundary=\"trim\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.restackVMIdataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.restackVMIdataset().dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change to dict for easy pass & layout!\n",
    "fSize=[500,500]\n",
    "# dims = ['yc','xc']\n",
    "# hv.Image(vmi.imgReduce.sel(run=89)).opts(height=fSize[0], aspect='square').redim.range(z=(0, 0.15))\n",
    "hv.Image(vmi.restackVMIdataset().sel(run=89, type='signal'), kdims = dims).opts(height=fSize[0], aspect='square').redim.range(z=(0, 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPlot = hv.Image(vmi.restackVMIdataset().sel(run=89, type='sub'), kdims = dims).opts(height=fSize[0], aspect='square').redim.range(z=(0, 0.15))\n",
    "(imgPlot.hist() + imgPlot.sample(xc=500) + imgPlot.sample(yc=552)).cols(1)\n",
    "# (imgPlot.hist() * imgPlot.sample(xc=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.restackVMIdataset().sel(run=89, type='sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imgPlot[450:650:5,400:600:5,...].to.curve().overlay().opts(tools=['hover'])  # Stack curves - hover not working?\n",
    "# imgPlot[450:650:5,400:600:5,...].to.curve()  # xc slices\n",
    "# imgPlot[450:650:5,400:600:5,...].to.curve(kdims='xc')  # yc slices\n",
    "# imgPlot[450:650:5,400:600:5,...].to.curve() + imgPlot[450:650:5,400:600:5,...].to.curve(kdims='xc')  # Nope\n",
    "# hv.Curve(imgPlot[450:650:5,400:600:5,...], kdims='xc', vdims='stacked')  # Nope\n",
    "# hv.Curve(vmi.restackVMIdataset().sel(run=89, type='sub')[450:650:5,400:600:5]) # Nope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPlot.sample(xc=503) * imgPlot.sample(yc=553)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(imgPlot.sample(xc=np.arange(500,503)), kdims=['yc','stacked'], vdims='xc') # * imgPlot.sample(yc=553)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = imgPlot.apply.sample(xc=np.arange(500,503)) #.collapse()\n",
    "hv.Curve(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPlot.sample(xc=np.arange(500,503)).layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testRestackHV = hv.Dataset(vmi.restackVMIdataset())\n",
    "testRestackHV.to(hv.Image, kdims=['xc','yc']).opts(colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fSize=[500,500]\n",
    "hv.Image(vmi.imgReduce[1].sel(run=89)).opts(height=fSize[0], aspect='square').redim.range(z=(0, 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hv.Image(vmi.imgReduce[2].sel(run=89)).opts(height=fSize[0], aspect='square').redim.range(z=(0, 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.imgStack[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is nice with slider, but range setting not working here?\n",
    "hv_ds = hv.Dataset(vmi.imgReduce[2].rename('downsampled'))\n",
    "hvImg = hv_ds.to(hv.Image, kdims=[\"yc\", \"xc\"]).redim.range(z=(0, 0.15)) #, dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvImg #.redim.range(z=(0, 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "bins = (np.arange(0, 1048.1, 1)-0.5,)*2\n",
    "imgStack = xr.DataArray(testX, dims=['x','y','run'], coords={'x':bins[0][0:-1], 'y':bins[1][0:-1], 'run':vmi.runs['proc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = [1,2,3,4]\n",
    "imgStack['norm'] = ('run', norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image gen method tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick single-shot image test...\n",
    "key = 89\n",
    "shot = 0\n",
    "# display(hv.Curve(vmi.data[key]['raw']['xc'][shot,:]))\n",
    "# display(hv.Curve(vmi.data[key]['raw']['yc'][shot,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.data[key]['raw']['xc'][shot,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.data[key]['raw']['yc'][shot,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.data[key]['raw']['yc'][shot,:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# 1.88 s ± 15.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# Current method (Elio's code)\n",
    "# See also psana, opal.raw.image(evt)\n",
    "dim = ['xc','yc']\n",
    "bins = (np.arange(0, 1048.1, 1)-0.5,)*2\n",
    "    \n",
    "d0 = np.array(vmi.data[key]['raw'][dim[0]])[shot,:] #[self.data[key]['mask']].flatten()\n",
    "d1 = np.array(vmi.data[key]['raw'][dim[1]])[shot,:] #[self.data[key]['mask']].flatten()\n",
    "\n",
    "img2d = np.histogram2d(d0,d1, bins = bins)[0]\n",
    "# hv.Image((np.histogram2d(d0,d1, bins = bins)[0]), dim).redim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = (np.arange(0, 1048.1, 1)-0.5,)*2\n",
    "# bins[0].size\n",
    "keys = [89, 91, 93, 97]\n",
    "imgArray = np.empty([bins[0].size, bins[1].size, len(keys)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Try with ints - should be faster...? ACTUALY SEEMS to be slower by several s, in this form at least.\n",
    "# https://numpy.org/devdocs/reference/generated/numpy.histogram2d.html#numpy.histogram2d\n",
    "# Current method (Elio's code)\n",
    "# See also psana, opal.raw.image(evt)\n",
    "dim = ['xc','yc']\n",
    "# bins = (np.arange(0, 1048.1, 1)-0.5,)*2\n",
    "# bins = (np.arange(0, 1048))*2\n",
    "bins = [1048, 1048]\n",
    "binRange = [[0,1048],[0,1048]]\n",
    "    \n",
    "d0 = np.array(vmi.data[key]['raw'][dim[0]]).astype('int').flatten() #[self.data[key]['mask']].flatten()\n",
    "d1 = np.array(vmi.data[key]['raw'][dim[1]]).astype('int').flatten() #[self.data[key]['mask']].flatten()\n",
    "\n",
    "img2d, xe, ye = np.histogram2d(d0,d1, bins = bins, range = binRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[img2d.sum(), img2d.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.data[key]['raw']['xc'][shot,:].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# 8.81 ms ± 515 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "\n",
    "# Try index method... WAY FASTER\n",
    "test2d = np.zeros([1048,1048])\n",
    "\n",
    "# Try indexing method - easy way to drop -9999 \"no hits\"?\n",
    "xhits = np.array(vmi.data[key]['raw']['xc'][shot,:]).astype(int)\n",
    "yhits = np.array(vmi.data[key]['raw']['yc'][shot,:]).astype(int)\n",
    "\n",
    "xhits = np.delete(xhits, np.where(xhits == -9999))\n",
    "yhits = np.delete(yhits, np.where(yhits == -9999))\n",
    "\n",
    "test2d[xhits, yhits] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img2d-test2d).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# Single shot: 1.88 s ± 15.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# All shots: 9.2 s ± 62.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# All shots, convert to int: 11.5 s ± 399 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# Current method (Elio's code)\n",
    "# See also psana, opal.raw.image(evt)\n",
    "dim = ['xc','yc']\n",
    "bins = (np.arange(0, 1048.1, 1)-0.5,)*2\n",
    "    \n",
    "# d0 = np.array(vmi.data[key]['raw'][dim[0]])[shot,:] #[self.data[key]['mask']].flatten()\n",
    "# d1 = np.array(vmi.data[key]['raw'][dim[1]])[shot,:] #[self.data[key]['mask']].flatten()\n",
    "d0 = np.array(vmi.data[key]['raw'][dim[0]]).flatten()\n",
    "d1 = np.array(vmi.data[key]['raw'][dim[1]]).flatten()\n",
    "\n",
    "\n",
    "img2d = np.histogram2d(d0,d1, bins = bins)[0]\n",
    "# hv.Image((np.histogram2d(d0,d1, bins = bins)[0]), dim).redim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# Single shot: 8.81 ms ± 515 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "# All shots 2D: 6.64 s ± 34.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# All shots with flatten() when indexing: 7.46 s ± 68.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# All shots with flatten() plus delete: 6.91 s ± 29.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# All shots 2D with masking: 7.82 s ± 30.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# All shots 2D with masking + compressed() index: 7.44 s ± 62.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# All shots 2D with boolean mult index: 5.56 s ± 103 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "\n",
    "# Try index method... WAY FASTER single shot, moderately faster all shots (but should be able to improve with Numba?)\n",
    "test2d = np.zeros([1050,1050])\n",
    "\n",
    "# Try indexing method - easy way to drop -9999 \"no hits\"?\n",
    "# xhits = np.array(vmi.data[key]['raw']['xc'][shot,:]).astype(int)\n",
    "# yhits = np.array(vmi.data[key]['raw']['yc'][shot,:]).astype(int)\n",
    "xhits = np.array(vmi.data[key]['raw']['xc']).astype(int)  #.flatten()\n",
    "yhits = np.array(vmi.data[key]['raw']['yc']).astype(int)  #.flatten()\n",
    "\n",
    "# xhits = np.delete(xhits, np.where(xhits == -9999))  # This only works for 1D case! May want to set NaNs instead?\n",
    "# yhits = np.delete(yhits, np.where(yhits == -9999))\n",
    "# xhits[np.where(xhits == -9999)] = np.nan  # nans also throw an error\n",
    "# yhits[np.where(yhits == -9999)] = np.nan\n",
    "# xhits[np.where(xhits == -9999)] = 1049  # Reindex to temp bin, then remove later\n",
    "# yhits[np.where(yhits == -9999)] = 1049\n",
    "\n",
    "# Try masked array\n",
    "# xhits = np.ma.masked_equal(xhits, -9999)  # Creates mask, but doesn't work directly as index - still need to flatten?\n",
    "# yhits = np.ma.masked_equal(yhits, -9999)\n",
    "\n",
    "\n",
    "# test2d[xhits, yhits] += 1\n",
    "# test2d[np.ma.filled(xhits,1049), np.ma.filled(yhits,1049)] += 1\n",
    "# test2d[xhits.compressed(), yhits.compressed()] += 1\n",
    "# test2d[xhits.flatten(), yhits.flatten()] += 1\n",
    "# test2d[~(xhits == -9999) * xhits, ~(yhits == -9999) * yhits] += 1   # This seems to work, but only uses 1st col to index? Miss A LOT of events.\n",
    "test2d[~(xhits == -9999) * xhits, ~(yhits == -9999) * yhits] = test2d[~(xhits == -9999) * xhits, ~(yhits == -9999) * yhits] + 1  # SAME RESULT\n",
    "# AH - probably due to inplace editing with repeated indicies. May need to accumulate or loop in 1 dim? Ugh.\n",
    "# MIGHT return to np.histogram2d for now!\n",
    "# test2d[(~(xhits == -9999) * xhits).flatten(), (~(yhits == -9999) * yhits).flatten()] += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(~(xhits == -9999)).sum(), (~(yhits == -9999)).sum()]  # * yhits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note a lot of missing elements here!\n",
    "test2d.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2d.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhits = np.array(vmi.data[key]['raw']['xc']).astype(int) \n",
    "# xhits = np.ma.masked_equal(xhits, -9999)\n",
    "# xhits.min()\n",
    "~(xhits == -9999) * xhits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xhits = np.array(vmi.data[key]['raw']['xc'])\n",
    "# hv.Curve((xhits > 0).sum(axis = 1)[0:1000])  # Events per shot\n",
    "# np.sum(np.where(xhits > 0),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note many shots top out (detector saturated). May want to use this as a filter parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D hist Numba tests - needs work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY AS NUMBA FUNCTION...\n",
    "# Single shot: 8.81 ms ± 515 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "# All shots 2D: 6.64 s ± 34.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# All shots with flatten() when indexing: 7.46 s ± 68.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# All shots with flatten() plus delete: 6.91 s ± 29.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# All shots 2D with masking: 7.82 s ± 30.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# All shots 2D with masking + compressed() index: 7.44 s ± 62.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "from numba import jit, njit, guvectorize\n",
    "\n",
    "# This is poor, since it just uses object mode\n",
    "# timeit same as raw function: 6.77 s ± 52.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# @jit\n",
    "# def numba2dhist(xhits, yhits):\n",
    "#     # Try index method... WAY FASTER single shot, moderately faster all shots (but should be able to improve with Numba?)\n",
    "#     test2d = np.zeros([1050,1050])\n",
    "#  REST AS PREVIOUSLY\n",
    "\n",
    "@jit(parallel = True)\n",
    "def numba2dhist(xhits, yhits, test2d):\n",
    "    # Try index method... WAY FASTER single shot, moderately faster all shots (but should be able to improve with Numba?)\n",
    "#     test2d = np.zeros([1050,1050])\n",
    "\n",
    "    # Try indexing method - easy way to drop -9999 \"no hits\"?\n",
    "    # xhits = np.array(vmi.data[key]['raw']['xc'][shot,:]).astype(int)\n",
    "    # yhits = np.array(vmi.data[key]['raw']['yc'][shot,:]).astype(int)\n",
    "#     xhits = np.array(vmi.data[key]['raw']['xc']).astype(int)  #.flatten()\n",
    "#     yhits = np.array(vmi.data[key]['raw']['yc']).astype(int)  #.flatten()\n",
    "\n",
    "    # xhits = np.delete(xhits, np.where(xhits == -9999))  # This only works for 1D case! May want to set NaNs instead?\n",
    "    # yhits = np.delete(yhits, np.where(yhits == -9999))\n",
    "    # xhits[np.where(xhits == -9999)] = np.nan  # nans also throw an error\n",
    "    # yhits[np.where(yhits == -9999)] = np.nan\n",
    "    # xhits[np.where(xhits == -9999)] = 1049  # Reindex to temp bin, then remove later\n",
    "    # yhits[np.where(yhits == -9999)] = 1049\n",
    "\n",
    "    # Try masked array\n",
    "    xhits = np.ma.masked_equal(xhits, -9999)  # Creates mask, but doesn't work directly as index - still need to flatten?\n",
    "    yhits = np.ma.masked_equal(yhits, -9999)\n",
    "\n",
    "\n",
    "    # test2d[xhits, yhits] += 1\n",
    "    # test2d[np.ma.filled(xhits,1049), np.ma.filled(yhits,1049)] += 1\n",
    "    test2d[xhits.compressed(), yhits.compressed()] += 1\n",
    "    # test2d[xhits.flatten(), yhits.flatten()] += 1\n",
    "    \n",
    "# As vectorized kernel... needs work!\n",
    "# @guvectorize([(int[:,:], int[:,:], int[:,:])], '(n,n),(n,n)->(m,m)')\n",
    "# def numba2dhist(xhits, yhits, output):\n",
    "#     xhits[np.where(xhits == -9999)] = 1049  # Reindex to temp bin, then remove later\n",
    "#     yhits[np.where(yhits == -9999)] = 1049\n",
    "    \n",
    "#     test2d[xhits, yhits] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "# xhits = np.array(vmi.data[key]['raw']['xc']).astype(int)  #.flatten()\n",
    "# yhits = np.array(vmi.data[key]['raw']['yc']).astype(int)  #.flatten()\n",
    "\n",
    "# test2d = np.zeros([1050,1050])\n",
    "\n",
    "# # same as raw function: 6.77 s ± 52.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# numba2dhist(xhits, yhits, test2d)\n",
    "\n",
    "# # TODO: try alternative codes, also guvectorise etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using masking, this will show hits per shot\n",
    "np.ma.clump_unmasked(xhits) #.compressed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image gen working (v1 with hv.Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fSize = [600,600]\n",
    "# vmi.eVMI['bgSub'][89].opts(height=fSize[0], aspect='square').redim.range(z=(0, 0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fSize = [600,600]\n",
    "\n",
    "# This times out...?\n",
    "for key in vmi.eVMI.keys():\n",
    "    print(key)\n",
    "    \n",
    "    if key.endswith('Norm'):\n",
    "        display(vmi.eVMI[key][89].opts(height=fSize[0], aspect='square').redim.range(z=(0, 0.005)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.eVMI['bgSub'][89].opts(height=fSize[0], aspect='square').redim.range(z=(0, 0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test for run 89 - looks to be working, different images for each case.\n",
    "\n",
    "Need to improve:\n",
    "\n",
    "- Cmapping (maybe log10?)\n",
    "- Image processing, use gaussian kernel?\n",
    "- Move to Xarray dataset image stack for more advanced/careful processing...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.filterOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=89\n",
    "vmi.eVMI['fullNorm'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.eVMI['bgNorm'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(vmi.eVMI['fullNorm'][key].data['z'] - vmi.eVMI['bgNorm'][key].data['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.data[89]['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(vmi.data[89]['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct data manipulation OK, returns numpy.ndarray\n",
    "# Seems easiest way to go for now.\n",
    "# May need dim too?\n",
    "testSub = vmi.data[89]['img'].data - vmi.data[89]['img'].data\n",
    "\n",
    "# Doesn't work with dataset\n",
    "# testSub = vmi.data[89]['img'].dataset - vmi.data[89]['img'].dataset  # FAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(testSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(testSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset org\n",
    "vmi.data[89]['img'].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test self subtraction - OK\n",
    "# testSub = vmi.data[89]['img'].transform(z=hv.dim('z')-hv.dim('z'))\n",
    "\n",
    "# Test subtraction of another hv dataset - NOT OK... returns something, but not correct\n",
    "# testSub = vmi.data[89]['img'].transform(z=hv.dim('z')-vmi.data[89]['img'].data) #['z'])\n",
    "\n",
    "# With dim - NOT OK, throws errors\n",
    "# testSub = vmi.data[89]['img'].transform(z=hv.dim('z')-vmi.data[89]['img'].data['z'])\n",
    "\n",
    "# With dim - NOT OK, throws errors\n",
    "# testSub = vmi.data[89]['img'].transform(z=hv.dim('z')-vmi.data[89]['img'].dim('z'))\n",
    "# testSub = vmi.data[89]['img'].transform(z=hv.dim('z')-vmi.data[89]['img'].dataset['z']) # Returns 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSub.data['z'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNorm = vmi.data[89]['img'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmi.data[89]['img'].dataset['z'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests with HV image transforms\n",
    "May use these, or just address data directly...\n",
    "\n",
    "See http://holoviews.org/user_guide/Transforming_Elements.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(backend='matplotlib', size=200)\n",
    "\n",
    "from scipy.misc import ascent\n",
    "\n",
    "stairs_image = hv.Image(ascent()[200:500, :], bounds=[0, 0, ascent().shape[1], 300], label=\"stairs\")\n",
    "stairs_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stairs_image.transform(z=hv.dim('z')-(hv.dim('z')*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stairs_image.reduce(x=np.mean)\n",
    "stairs_image.reduce(x=np.subtract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "class image_filter(hv.Operation):\n",
    "    \n",
    "    sigma = param.Number(default=5)\n",
    "    \n",
    "    type_ = param.String(default=\"low-pass\")\n",
    "\n",
    "    def _process(self, element, key=None):\n",
    "        xs = element.dimension_values(0, expanded=False)\n",
    "        ys = element.dimension_values(1, expanded=False)\n",
    "        \n",
    "        # setting flat=False will preserve the matrix shape\n",
    "        data = element.dimension_values(2, flat=False)\n",
    "        \n",
    "        if self.p.type_ == \"high-pass\":\n",
    "            new_data = data - ndimage.gaussian_filter(data, self.p.sigma)\n",
    "        else:\n",
    "            new_data = ndimage.gaussian_filter(data, self.p.sigma)\n",
    "        \n",
    "        label = element.label + \" ({} filtered)\".format(self.p.type_)\n",
    "        # make an exact copy of the element with all settings, just with different data and label:\n",
    "        element = element.clone((xs, ys, new_data), label=label)\n",
    "        return element\n",
    "\n",
    "stairs_map = hv.HoloMap({sigma: image_filter(stairs_image, sigma=sigma)\n",
    "                         for sigma in range(0, 12, 1)}, kdims=\"sigma\")\n",
    "\n",
    "stairs_map.opts(framewise=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LOCAL clone LCLS-II py3",
   "language": "python",
   "name": "psana-4.0.8-local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
